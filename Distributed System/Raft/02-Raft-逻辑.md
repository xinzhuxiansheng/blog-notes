## 选举    

节点有3种角色： Leader、Candidate（Leader候选人）、Follower。每个节点在任何时候都只可能是这3钟角色中的一种。     

在稳定状态下，存在一个 Leader 节点和多个 Follower 节点，Leader 节点通过心跳消息与 Follower 节点保持联系。    

包括心跳信息在内，Raft 算法中节点之间所使用的消息主要有以下两种：       
(1): RequestVote，即请求其他节点给自己投票，一般由 Candidate 节点发出。    
(2): AppendEntries，字面意思是增加条目，也就是用于日志复制，但在增加日志条目数量为0时也作为心跳消息，一般只由 Leader 节点发出。  


## 逻辑时钟 term 

Raft算法中的选举有一个 `term参数`，其类型为整数。这是一个逻辑时钟值，全局递增，准备来说是 Lamport Timestamp 的一个变体。   

Lamport Timestamp 的算法很简单。假设有多个进程要维护一个全局时间，首先要让每个进程有一个全局时间的副本。算法流程吐下。                  
(1) 每个进程在事件发生时递增自己本地的时间副本。   
(2) 当进程发送消息时，带上自己本地的时间副本。   
(3) 当进程收到消息时，比较消息中的时间值和自己本地的时间副本，选择比较大的时间值加上1，并更新自己的时间副本。      

整个过程对应到Raft 算法中如下。  
(1) 在开始选举时，增加 term。 
(2) 发送 RequestVote 消息时，带上自己的 term (递增过后的 term)。   
(3) 节点在收到 RequestVote 消息或 AppendEntries 消息时，比较自己本地的 term 和消息中的 term，选择最大的 term 并更新自己本地的 term (注意，此时没有加 1 操作)            
这样即使服务器间时钟不一致，系统也可以安全的推进逻辑时间。        

## 选举中的 term 和角色迁移   

Raft算法中主要使用 term作为 Leader 节点的任期号，选举中需要 term参数以及需要使其递增的原因可以理解如下：    
(1) 因为Follower 节点不能重复投票（一节点一票制），所以如果没有新的选举 term，节点在第一次选举后不会再给其他节点投票。     
(2) 递增之后可以避免给比较早的 term 投票，比如因为慢速网络或者网络分区迟到的投票请求。    

在选举的过程中，节点的角色会有所变化：   
（1）系统启动时所有节点都是 Follower 节点。 
（2）当没有收到来自 Leader节点的心跳信息，即心跳超时时，Follower 节点变成 Candidate 节点，即自荐成为选举的候选人。  
（3）Candidate 节点收到过半的支持（包括自己）后，变成 Leader 节点。     

正常情况的选举到此结束。出现 Leader节点之后，Leader 节点会发送心跳消息给其他节点，防止其他节点从 Follower节点变成 Candidate节点。     
在步骤（3）中，如果 Candidate 节点没有得到过半支持，如果四个节点的集群中，两个 Candidate 节点分别得到 2票，票数没有过半，无法选出 Leader节点，此时 Candidate节点选举超时，进入下一轮选举。   

票数过半的现象在 Raft 算法中被称为 split vote（分割选举），在偶数个节点的集群中有可能发生，Raft 算法使用`随机选举超时`来降低 split vote 出现的概率。        
Candidate 节点和 Leader 节点在收到 term 比自己本地的 term 大的消息后，会退化为 Follower 节点，这往往发生在网络分区的情况下。   


## 选举超时  

4个节点的集群同时出现2个 Candidate节点，这2个节点各自获取2票时，只能等待下一次选举。但是可能下一次选举还是2票对2票，最坏的情况是无限次2票对2票，那就无法正常选出 Leader节点了，为了减少这类问题出现的概率，Raft 算法中的选举时间是一个`区间的随机值`，比如3-4秒，则每个节点可能选举超时有3秒，3.1秒，3.5秒等。这样成为 Candidate节点的时间点就被错开了，提高了选出 Leader节点的概率。        

在选出 Leader 节点之后，各个节点需要在最短的时间内获取新 Leader 节点的信息，否则选举超时又会进入一轮选举，即要求心跳消息间隔 << 最小选举间隔。"<<" 这里表示远小于。     


## 日志条目 

所有来自客户端的数据变更请求都会被当作一个日志条目追加到节点日志中。   

Raft 算法中的日志条目除了操作还有 term，也就是之前提到的选举中用的 Leader 节点的任期号。 日志中的 term 也会被用于日志比较，新 term的日志总比旧 term 的日志新。   

日志条目分以下两种状态：   
（1）已追加但是尚未持久化  
（2）已持久化     

Raft 算法中的节点会维护一个已持久化的日志条目索引，即 commitIndex。 小于等于 commitIndex 的日志条目被人为是已提交，或者说是有效的日志条目

需要注意的是，在 Raft算法中，系统启动时 commitIndex 为0 ，所以不管日志是否在文件中，系统启动时日志条目都被认为是“未提交”的状态。   

## 复制进度  
为了跟踪各节点的复制进度，Leader 负责记录各个节点的 nextIndex（下一个需要复制日志条目的索引）和 matchIndex（已匹配日志的索引）

选出 Leader 节点后，Leader 节点会重置（或者说新建）各节点的 nextIndex 和 matchIndex，也就是把 matchIndex 设置为0，nextIndex 设置为 Leader节点接下来的日志条目索引，然后通过和各节点之间发送 AppendEntries 消息来更新 nextIndex 和 matchIndex。     

matchIndex 并不总是和 nextIndex 邻接， 比如在复制刚开始的时候。     

复制过程中，Raft 算法采用的是乐观策略，认为 Follower 节点和 Leader节点日志不会相差太大。把 nextIndex 设置成最大值，然后不断回退到 nextIndex，以找到匹配的日志索引。这时 matchIndex 会瞬间从 0 跳到一个比较大的值，然后类似于进度条一样批量同步日志并更新进度。    

当系统处理达到稳定状态时， Leader 跟踪的各个节点的 matchIndex 与 Leader 的 commitIndex 一致，nextIndex 与 Leader 节点的下一条日志的索引一致。 此时，上面的复制进度条就会像100%复制完成一样。    

Raft 算法针对回退时一条一条回退可能导致处理比较慢的问题，提出一次回退一个 term 的方案。 不过实际出现这种情况的可能性比较小，所以没有必要使用。      


## Leader 节点不能使用之前 term的日志条目决定 commitIndex   
在 Raft算法中，要求节点启动时，commitIndex 一开始为0，而不是节点日志中最后一条日志的索引。     

一个简单的解释是，在 Leader 节点每次收到数据变更请求时，都往磁盘写入日志，但在日志条目还没有过半复制到其他节点时，不可以认为最后被写入的日志条目是有效的。特别是 Leader 节点有可能在过半复制完成前宕机，而原来的 Leader 节点重启后，不可以认为自己的日志中最后一条日志条目是有效的，因为过半复制完成前自己就宕机了。    

这里还牵扯到以下两个问题。     
（1）节点之间日志不同时，以哪个节点为准？    
可以用一句话回答：以 Leader 节点为准。所以 Follower 节点与 Leader 节点不同的日志条目，会被 Leader 节点的日志条目覆盖。       

（2）Leader 节点如何决定 commitIndex？  
该问题的前提是，Follower 节点会跟随 Leader 节点的 commitIndex，所以重点看 Leader 节点如何更新 commitIndex。   


## 需要持久化的状态数据  
每台服务器启动或者关闭时，必须保存的数据如下：   
（1）currentTerm：当前选举的 term，推断类型为整数（integer），初始为0。    
（2）votedFor：投过票给谁。     
（3）log[]：日志条目，注意第一个日志的 id 为1。 
一般来说，votedFor 的内容应该是服务器成员的 ID 或者成员的 IP地址加端口。不过从其他状态数据来看，这里也可能是整数，既成员列表中服务器的索引号。    

## 服务器可变状态数据  
每台服务器在运行中需要记录的数据如下：  
（1）commitIndex：已提交的最高的日志索引，推断类型为整数，初始为0. 
（2）lastApplied：已应用的最高的日志索引，推断类型为整数，初始为0. 


## 集群成员列表   
对于固定的成员列表来说，从环境变量或者配置文件中读取即可。但是如果成员变量可变，那么为了在集群启动时读取，就需要考虑在什么地方存储最新的成员列表，可选择的方式有以下3种：       
（1）与状态数据一样持久化。    
（2）在日志中存放差分数据，即增减的服务器。   
（3）在日志中存放变更前的列表和差分数据。  
这里的选项（2）和（3）是在实现了集群成员变更之后给出的方案。因为集群成员变更会以日志的方式通知所有集群内的节点，所以理论上只需查看相关集群成员变更的日志，即可计算出最新的成员列表。如果没有集群成员变更的日志，就使用环境变量或者配置文件中的初始配置。    


## 组件分析   
（1）通信组件    
（2）日志组件  
（3）定时器组件：拥有3个时间配置，即选举超时区间和日志复制间隔。    
（4）成员表组件：拥有成员表和日志复制进度表。  
（5）一致性算法组件：核心组件，拥有除上述组件所拥有的状态数据和配置以外的所有状态数据。     

