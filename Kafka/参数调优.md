**正文**

[TOC]

```shell
#对外提供的服务入口地址
listeners=PLAINTEXT://:9093
#zk连接地址 注意zk的命名空间设置
zookeeper.connect=zk-0.zk-svc.default.svc.cluster.local:2181,zk-1.zk-svc.default.svc.cluster.local:2181,zk-2.zk-svc.default.svc.cluster.local:2181
#存放消息日志文件的地址
log.dir=/var/lib/kafka
#是否开启自动创建topic(true)
auto.create.topics.enable=true
#是否开启分自动leader再均衡 (true)
auto.leader.rebalance.enable=true
#指定执行后台任务的线程数(10)
background.threads=10
#消息的压缩类型，kafka支持的压缩类型有Gzip,Snappy,LZ4等，默认值“producer”表示根据生产者使用的压缩类型压缩，也就是说，生产者不管是否压缩消息，或者使用何种压缩方式都被会broker端继承，“uncompressed”表示不启用压缩
compression.type=producer
#是否可以删除topic(true)
delete.topic.enable=false
#检查leader是否分布不均衡的周期(300)
leader.imbalance.check.interval.seconds=300
#允许leader不均衡的比例，若超过这个值就会触发leader再均衡的操作，前提是auto.leader.rebalance.enable参数也要设定为true(10)
leader.imbalance.per.broker.percentage=10
#如果日志文件中的消息在存入磁盘前的数量达到这个参数所设定的阂值时，则会强制将这些刷新日志文件到磁盘中。消息在写入磁盘前还要经历 一 层操作系统页缓存，如果期间发生掉电，则这些页缓存中的消息会丢失，调小这个参数的大小会增大消息的可靠性，但也会降低系统的整体性能
log.flush.interval.messages=9223372036854775807

log.flush.offset.checkpoint.interval.ms=60000
#检查日志文件是否需要刷新的时间间隔(Long.MAX_VALUE)
log.flush.scheduler.interval.ms=9223372036854775807
#日志文件的最大保留大小，分区级别，注意与log.segment.bytes的区别
log.retention.bytes=-1
#日志文件的留存时间，单位为小时
log.retention.hours=168
#经过多长时间之后会强制新建一个日志分段，默认值为7天(168)
log.roll.hours=168

log.roll.jitter.hours=0
#日志分段文件的最大值，超过这个值会强制创建一个新的日志分段
log.segment.bytes=1073741824
#从操作系统删除文件前的等待时间
log.segment.delete.delay.ms=60000
#消息最大的字节大小
message.max.bytes=1000012
#ISR集合中最少的副本树
min.insync.replicas=1
#处理请求的线程数，包含磁盘I/O
num.io.threads=8
#处理接受和返回响应的线程数
num.network.threads=3

num.recovery.threads.per.data.dir=1
num.replica.fetchers=1
--override offset.metadata.max.bytes=4096 \
--override offsets.commit.required.acks=-1 \
--override offsets.commit.timeout.ms=5000 \
--override offsets.load.buffer.size=5242880 \
--override offsets.retention.check.interval.ms=600000 \
--override offsets.retention.minutes=1440 \
--override offsets.topic.compression.codec=0 \
--override offsets.topic.num.partitions=50 \
--override offsets.topic.replication.factor=3 \
--override offsets.topic.segment.bytes=104857600 \
--override queued.max.requests=500 \
--override quota.consumer.default=9223372036854775807 \
--override quota.producer.default=9223372036854775807 \
--override replica.fetch.min.bytes=1 \
--override replica.fetch.wait.max.ms=500 \
--override replica.high.watermark.checkpoint.interval.ms=5000 \
--override replica.lag.time.max.ms=10000 \
--override replica.socket.receive.buffer.bytes=65536 \
--override replica.socket.timeout.ms=30000 \
--override request.timeout.ms=30000 \
--override socket.receive.buffer.bytes=102400 \
--override socket.request.max.bytes=104857600 \
--override socket.send.buffer.bytes=102400 \
--override unclean.leader.election.enable=true \
--override zookeeper.session.timeout.ms=6000 \
--override zookeeper.set.acl=false \
--override broker.id.generation.enable=true \
--override connections.max.idle.ms=600000 \
--override controlled.shutdown.enable=true \
--override controlled.shutdown.max.retries=3 \
--override controlled.shutdown.retry.backoff.ms=5000 \
--override controller.socket.timeout.ms=30000 \
--override default.replication.factor=1 \
--override fetch.purgatory.purge.interval.requests=1000 \
--override group.max.session.timeout.ms=300000 \
--override group.min.session.timeout.ms=6000 \
--override inter.broker.protocol.version=0.10.2-IV0 \
#是否开启日志清理的功能
log.cleaner.backoff.ms=15000
--override log.cleaner.dedupe.buffer.size=134217728 \
--override log.cleaner.delete.retention.ms=86400000
#是否开启日志清理的功能
log.cleaner.enable=true
--override log.cleaner.io.buffer.load.factor=0.9 \
--override log.cleaner.io.buffer.size=524288 \
--override log.cleaner.io.max.bytes.per.second=1.7976931348623157E308 \
--override log.cleaner.min.cleanable.ratio=0.5 \
--override log.cleaner.min.compaction.lag.ms=0 \
#用于日志清理的后台线程数
log.cleaner.threads=1
#日志清理策略，还有一个可选项为compact,表示日志压缩
log.cleanup.policy=delete
#每隔多少个字节的消息量写入就添加一条索引
log.index.interval.bytes=4096
#索引文件的最大值
log.index.size.max.bytes=10485760
log.message.timestamp.difference.max.ms=9223372036854775807
#消息中的时间戳类型，另一个可选项为LogAppendTime，CreateTime表示消息创建的时间，LogAppendTime表示消息追加到日志中的时间
log.message.timestamp.type=CreateTime
log.preallocate=false
#日志清理的检查周期
log.retention.check.interval.ms=300000
max.connections.per.ip=2147483647
#topic默认的分区数
num.partitions=1
producer.purgatory.purge.interval.requests=1000
--override replica.fetch.backoff.ms=1000 \
--override replica.fetch.max.bytes=1048576 \
--override replica.fetch.response.max.bytes=10485760 \
--override reserved.broker.max.id=1000

```