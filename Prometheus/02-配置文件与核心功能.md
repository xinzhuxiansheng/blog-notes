## 配置文件与核心功能   

### 1.全局配置文件    

```
global:
  # How frequently to scrape targets by default.
  [ scrape_interval: <duration> | default = 1m ]

  # How long until a scrape request times out.
  [ scrape_timeout: <duration> | default = 10s ]

  # How frequently to evaluate rules.
  [ evaluation_interval: <duration> | default = 1m ]

  # The labels to add to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    [ <labelname>: <labelvalue> ... ]

  # File to which PromQL queries are logged.
  # Reloading the configuration will reopen the file.
  [ query_log_file: <string> ]

  # An uncompressed response body larger than this many bytes will cause the
  # scrape to fail. 0 means no limit. Example: 100MB.
  # This is an experimental feature, this behaviour could
  # change or be removed in the future.
  [ body_size_limit: <size> | default = 0 ]

  # Per-scrape limit on number of scraped samples that will be accepted.
  # If more than this number of samples are present after metric relabeling
  # the entire scrape will be treated as failed. 0 means no limit.
  [ sample_limit: <int> | default = 0 ]

  # Per-scrape limit on number of labels that will be accepted for a sample. If
  # more than this number of labels are present post metric-relabeling, the
  # entire scrape will be treated as failed. 0 means no limit.
  [ label_limit: <int> | default = 0 ]

  # Per-scrape limit on length of labels name that will be accepted for a sample.
  # If a label name is longer than this number post metric-relabeling, the entire
  # scrape will be treated as failed. 0 means no limit.
  [ label_name_length_limit: <int> | default = 0 ]

  # Per-scrape limit on length of labels value that will be accepted for a sample.
  # If a label value is longer than this number post metric-relabeling, the
  # entire scrape will be treated as failed. 0 means no limit.
  [ label_value_length_limit: <int> | default = 0 ]

  # Per-scrape config limit on number of unique targets that will be
  # accepted. If more than this number of targets are present after target
  # relabeling, Prometheus will mark the targets as failed without scraping them.
  # 0 means no limit. This is an experimental feature, this behaviour could
  # change in the future.
  [ target_limit: <int> | default = 0 ]

# Rule files specifies a list of globs. Rules and alerts are read from
# all matching files.
rule_files:
  [ - <filepath_glob> ... ]

# Scrape config files specifies a list of globs. Scrape configs are read from
# all matching files and appended to the list of scrape configs.
scrape_config_files:
  [ - <filepath_glob> ... ]

# A list of scrape configurations.
scrape_configs:
  [ - <scrape_config> ... ]

# Alerting specifies settings related to the Alertmanager.
alerting:
  alert_relabel_configs:
    [ - <relabel_config> ... ]
  alertmanagers:
    [ - <alertmanager_config> ... ]

# Settings related to the remote write feature.
remote_write:
  [ - <remote_write> ... ]

# Settings related to the remote read feature.
remote_read:
  [ - <remote_read> ... ]

# Storage related settings that are runtime reloadable.
storage:
  [ tsdb: <tsdb> ]
  [ exemplars: <exemplars> ]

# Configures exporting traces.
tracing:
  [ <tracing_config> ]
```


### 2.scrape_configs    
参考官方文档 https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config    

重新标签的意义？    
* 重命名标签名  
* 删除标签  
* 过滤目标  




### 3.relabel_configs
允许在采集之前对任何目标以及标签进行修改    


### 4.服务发现  
在`configuration`以 `*_sd.config`结尾的的参数，表示的是服务发现功能 

在 Prometheus 配置中，以 `_sd_config` 结尾的配置项是用于“服务发现”（Service Discovery）的。Prometheus 提供了一组广泛的服务发现选项，这使得 Prometheus 能够自动发现目标实例，而不是静态地配置它们。这在动态变化的环境中（如 Kubernetes）非常有用。

每种服务发现机制都有其自己的 `_sd_config` 配置，它们定义了如何连接到那个服务发现系统以及如何获取和解释它提供的数据。以下是一些常用的 `_sd_config` 类型和它们的用途：

1. **`static_configs`**：
   - 这是最基本的服务发现配置。它允许你静态地列出目标实例的地址。
   
2. **`file_sd_config`**：
   - 允许 Prometheus 从 JSON/ YAML 文件中动态加载目标实例。这些文件可以由其他系统生成，并定期更新。

3. **`kubernetes_sd_config`**：
   - 用于从 Kubernetes API 服务器发现服务。它能自动发现 Kubernetes 集群中的节点、Pod、Service 等，并根据需要自动更新目标实例。

4. **`consul_sd_config`**：
   - 允许 Prometheus 从 Consul 服务发现中动态地加载目标实例。

5. **`ec2_sd_config`**：
   - 用于从 Amazon EC2 API 中发现 EC2 实例。

6. **`gce_sd_config`**：
   - 用于从 Google Compute Engine (GCE) API 中发现 GCE 实例。

7. **`azure_sd_config`**：
   - 用于从 Azure 的 APIs 中发现 VM 实例。

8. **`openstack_sd_config`**：
   - 用于从 OpenStack 的 APIs 中发现 Nova 实例。

...等等。每一种 `_sd_config` 类型都有其自己的特定配置参数，这些参数用于控制如何连接到相应的服务发现系统以及如何处理从该系统获得的数据。

这里是一个简单的例子，使用 `kubernetes_sd_config` 来自动发现 Kubernetes 集群中的 Pod 实例：

```yaml
scrape_configs:
  - job_name: 'kubernetes-pods'
    kubernetes_sd_config:
      api_server: 'https://kubernetes.default.svc'
      role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
```

在这个例子中，Prometheus 通过 Kubernetes API 服务器自动发现集群中的 Pod，并使用一些 `relabel_configs` 规则来决定哪些 Pod 应该被抓取。

总之，`*_sd_config` 结尾的配置项在 Prometheus 配置中用于定义服务发现的逻辑，它们使 Prometheus 能够适应动态变化的环境，自动更新抓取目标。    



refer   
1.https://prometheus.io/docs/prometheus/latest/configuration/configuration/#configuration   



